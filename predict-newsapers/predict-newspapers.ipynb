{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf04f22",
   "metadata": {},
   "source": [
    "# Predict Newspapers from Newspaper Articles\n",
    "\n",
    "You can find the Jupyter Notebook for this lesson here - run it on Binder here.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "The [climate-news-db](https://www.climate-news-db.com/) is a dataset of newspapers on climate change, created & maintained by [Data Science South](https://www.datasciencesouth.com/).\n",
    "\n",
    "## Project Goals\n",
    "\n",
    "We are given a newspaper article without knowing which newspaper it comes from.\n",
    "\n",
    "We must predict which newspaper a newspaper article is from - this is a classification problem.  \n",
    "\n",
    "## Project Plan\n",
    "\n",
    "In this project, we will iterate through three pipelines.  Each iteration will build on top of the previous implementation.\n",
    "\n",
    "### Iteration One\n",
    "\n",
    "- split our data into development and holdout datasets,\n",
    "- simple data cleaning and feature engineering,\n",
    "- train & test a dummy model & random forest.\n",
    "\n",
    "### Iteration Two\n",
    "\n",
    "- refactor the first iteration,\n",
    "- add cross validation.\n",
    "\n",
    "### Iteration Three\n",
    "\n",
    "- refactor the second iteration,\n",
    "- add hyperparameter tuning.\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Our dataset here is a snapshot of the [climate-news-db](https://www.climate-news-db.com/) database, which is a SQLite database called `db.sqlite`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6804f9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw article data:\n",
      "(8534, 9)\n",
      "Index(['id', 'body', 'headline', 'article_name', 'article_url',\n",
      "       'date_published', 'date_uploaded', 'newspaper_id', 'article_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# setup custom options for display of column width - useful for the article body text\n",
    "pd.set_option(\"display.max_columns\", 24)\n",
    "pd.set_option(\"display.max_colwidth\", 40)\n",
    "pd.set_option(\"display.width\", None)\n",
    "\n",
    "# establish a connection to the SQLite database\n",
    "conn = sqlite3.connect(\"./data/db.sqlite\")\n",
    "\n",
    "# read the article table using pandas\n",
    "articles = pd.read_sql_query(\"SELECT * from article\", conn)\n",
    "\n",
    "print(\"raw article data:\")\n",
    "print(articles.shape)\n",
    "print(articles.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc0fc73",
   "metadata": {},
   "source": [
    "We can use `pd.DataFrame.sample()` to show three random articles with their headline and body text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab028d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 was tied for the hottest year ever recorded -- but the disasters fueled by climate change set it apart\n",
      "Global average temperatures last year were tied for the hottest on record, capping what was also the planet's hottest decade ever recorded, according to new data analysis released Friday.The last six years are now the hottest six on record,\n",
      "\n",
      "Is it climate change or global warming? How science and a secret memo shaped the answer\n",
      "As director of the Yale Program on Climate Change Communication, Anthony Leiserowitz gets brought in to a lot of conversations about the topic. He shapes stories about it with other scientist for publication. He talks to CEOs and politician\n",
      "\n",
      "Greenpeace warns of ‘dangerous temperatures’ for Tokyo, Beijing\n",
      "Study shows hot weather is starting earlier and that more frequent heat waves are likely. Scorching temperatures are becoming much more frequent in cities across East Asia, an analysis from Greenpeace East Asia has found, with the environme\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = articles.sample(3)\n",
    "\n",
    "for n in range(samples.shape[0]):\n",
    "    sample = samples.iloc[n]\n",
    "    print(sample['headline'])\n",
    "    print(sample['body'][:240])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238708f",
   "metadata": {},
   "source": [
    "## Merging with Newspaper Metadata\n",
    "\n",
    "Our articles dataset only refers to newspaper by an integer ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bf1639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'body', 'headline', 'article_name', 'article_url',\n",
      "       'date_published', 'date_uploaded', 'newspaper_id', 'article_length'],\n",
      "      dtype='object')\n",
      "0        3\n",
      "1        3\n",
      "2        3\n",
      "3        3\n",
      "4        3\n",
      "        ..\n",
      "8529    16\n",
      "8530    16\n",
      "8531    16\n",
      "8532    16\n",
      "8533    16\n",
      "Name: newspaper_id, Length: 8534, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(articles.columns)\n",
    "print(articles['newspaper_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84333c",
   "metadata": {},
   "source": [
    "This integer ID is the primary key of a table called `newspaper` - we can use it to join the two tables together, giving us a variable `data` with columns from both tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3683a389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged article and newspaper data:\n",
      "Index(['id_x', 'body', 'headline', 'article_name', 'article_url',\n",
      "       'date_published', 'date_uploaded', 'newspaper_id', 'article_length',\n",
      "       'id_y', 'name', 'newspaper', 'newspaper_url', 'color', 'article_count',\n",
      "       'average_article_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "newspapers = pd.read_sql_query(\"SELECT * from newspaper\", conn)\n",
    "data = pd.merge(articles, newspapers, left_on=\"newspaper_id\", right_on=\"id\")\n",
    "data = data.rename({\"fancy_name\": \"newspaper\"}, axis=1)\n",
    "assert data.shape[0] == articles.shape[0]\n",
    "print(\"merged article and newspaper data:\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79824304",
   "metadata": {},
   "source": [
    "## Split Out a Holdout Set\n",
    "\n",
    "Before we do any data science work (including data exploration), we will split off a holdout set.\n",
    "\n",
    "This holdout data will sit untouched for as long as possible - when we need it, we can use it to evaluate our model on data it didn't see during model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf998f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "home = pathlib.Path(\"./data\")\n",
    "home.mkdir(exist_ok=True)\n",
    "dev, ho = train_test_split(\n",
    "  data,\n",
    "  test_size=0.2,\n",
    "  random_state=42,\n",
    ")\n",
    "dev.to_parquet(home / \"dev.parquet\")\n",
    "ho.to_parquet(home / \"holdout.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f3878",
   "metadata": {},
   "source": [
    "### EDA on the Development Set\n",
    "\n",
    "We continue our work using only the development dataset.\n",
    "\n",
    "In supervised learning, the target reigns supreme.  Understanding the target is a primary concern during EDA.\n",
    "\n",
    "We can look at how our target is distributed using the counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b17e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Guardian              757\n",
      "Stuff.co.nz               589\n",
      "Sky News Australia        543\n",
      "The New York Times        487\n",
      "The Daily Mail            477\n",
      "The BBC                   450\n",
      "CNN                       430\n",
      "The Washington Post       414\n",
      "Al Jazeera                411\n",
      "Fox News                  399\n",
      "NewsHub.co.nz             358\n",
      "The Independent           327\n",
      "Deutsche Welle            324\n",
      "The Atlantic              318\n",
      "The Economist             293\n",
      "The New Zealand Herald    250\n",
      "Name: newspaper, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet(home / \"dev.parquet\")\n",
    "data = data[\n",
    "    [\"headline\", \"body\", \"article_url\", \"date_published\", \"newspaper\", \"newspaper_url\"]\n",
    "]\n",
    "print(data[\"newspaper\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ccf497",
   "metadata": {},
   "source": [
    "From the results above, we can see that our target is not equally distributed among newspapers.  \n",
    "\n",
    "This finding leads us to choosing to use a stratified split during training later on.\n",
    "\n",
    "## Iteration One\n",
    "\n",
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d44411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(\n",
    "  data,\n",
    "  test_size=0.2,\n",
    "  random_state=42,\n",
    "  stratify=data[\"newspaper\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07e127",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "For this first iteration of our pipeline, we will keep things simple at the feature engineering stage.\n",
    "\n",
    "We transform our target newspaper column using label encoding - making our target column a column of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65cebda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      target            newspaper\n",
      "1089       8              The BBC\n",
      "1631       1                  CNN\n",
      "5334       4        NewsHub.co.nz\n",
      "8245      15  The Washington Post\n",
      "5067      12      The Independent\n",
      "...      ...                  ...\n",
      "3991      11         The Guardian\n",
      "1503       8              The BBC\n",
      "3463       3             Fox News\n",
      "277        0           Al Jazeera\n",
      "2005       1                  CNN\n",
      "\n",
      "[5461 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target_encoder = LabelEncoder()\n",
    "target_tr = target_encoder.fit_transform(train[\"newspaper\"])\n",
    "train['target'] = target_tr\n",
    "print(train[[\"target\", \"newspaper\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fb0d2",
   "metadata": {},
   "source": [
    "We then create features using tf-idf (term frequency–inverse document frequency):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "606a2bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5461, 139311)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1, 2))\n",
    "features_tr = tfidf.fit_transform(train[\"body\"])\n",
    "print(features_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc55114",
   "metadata": {},
   "source": [
    "### Transform the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202e7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_te = target_encoder.transform(test[\"newspaper\"])\n",
    "features_te = tfidf.transform(test[\"body\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf9496",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "Now we have both our target and features, we can train a simple dummy model as a baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349bec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier() scores tr: 0.11096868705365318 te: 0.11054172767203514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mdl = DummyClassifier()\n",
    "mdl.fit(features_tr, target_tr)\n",
    "score_tr = mdl.score(features_tr, target_tr)\n",
    "score_te = mdl.score(features_te, target_te)\n",
    "print(f\"{mdl} scores tr: {score_tr} te: {score_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e38cf",
   "metadata": {},
   "source": [
    "```\n",
    "DummyClassifier() scores tr: 0.1126167368613807 te: 0.11273792093704246\n",
    "```\n",
    "\n",
    "### Train Random Forest\n",
    "\n",
    "Our first machine learning model is a random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98aaf5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_jobs=-1, random_state=42) scores tr: 1.0 te: 0.8089311859443631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mdl = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "mdl.fit(features_tr, target_tr)\n",
    "score_tr = mdl.score(features_tr, target_tr)\n",
    "score_te = mdl.score(features_te, target_te)\n",
    "print(f\"{mdl} scores tr: {score_tr} te: {score_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b2dd0",
   "metadata": {},
   "source": [
    "```\n",
    "RandomForestClassifier(n_jobs=-1, random_state=42) scores tr: 1.0 te: 0.7847730600292826\n",
    "```\n",
    "\n",
    "At this point, the experienced developer will see and note the repeated code for training the baseline dummy classifier and the random forest.\n",
    "\n",
    "This repetition is a good candidate for refactoring into a function in our second iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c104f72",
   "metadata": {},
   "source": [
    "### Should We Look at the Holdout Set Now?\n",
    "\n",
    "This point is the natural end of our first pipeline - we don't plan on adding anything until we start our second iteration.\n",
    "\n",
    "We could grab our holdout set and evaluate our model generalization again - but it's probably not worth it at this stage.  Each time we evaluate on the holdout and iterate again, we risk starting to overfit to the holdout.\n",
    "\n",
    "For this reason, we will not evaluate on the holdout here.\n",
    "\n",
    "## Iteration Two\n",
    "\n",
    "The results of our first pipeline proved promising - we can show that a naive implementation (no feature engineering, one model with no hyperparameter tuning) can learn from our dataset.\n",
    "\n",
    "Our second implementation will start with a refactor of the first implementation - taking what we have done and combining it with the lessons we learnt during our first implementation.\n",
    "\n",
    "### Read & Merge Dataset\n",
    "\n",
    "First we will refactor our code to read the dataset from the sqlite database and merge the tables together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "967c3af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles sqlite table: (8534, 9)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset():\n",
    "    conn = sqlite3.connect(\"./data/db.sqlite\")\n",
    "    articles = pd.read_sql_query(\"SELECT * from article\", conn)\n",
    "    print(f\"articles sqlite table: {articles.shape}\")\n",
    "    newspapers = pd.read_sql_query(\"SELECT * from newspaper\", conn)\n",
    "    data = pd.merge(articles, newspapers, left_on=\"newspaper_id\", right_on=\"id\")\n",
    "    data = data[\n",
    "        [\n",
    "            \"headline\",\n",
    "            \"body\",\n",
    "            \"article_url\",\n",
    "            \"date_published\",\n",
    "            \"fancy_name\",\n",
    "            \"newspaper_url\",\n",
    "            \"newspaper_id\",\n",
    "        ]\n",
    "    ]\n",
    "    data = data.rename({\"fancy_name\": \"newspaper\"}, axis=1)\n",
    "    return data\n",
    "\n",
    "data = create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a89a3b",
   "metadata": {},
   "source": [
    "### Create Holdout\n",
    "\n",
    "We also refactor the code to create a holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf19304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles sqlite table: (8534, 9)\n"
     ]
    }
   ],
   "source": [
    "def create_holdout(data, random_state=42):\n",
    "    return train_test_split(\n",
    "      data,\n",
    "      test_size=0.2,\n",
    "      random_state=42,\n",
    "    )\n",
    "\n",
    "data = create_dataset()\n",
    "dev, holdout = create_holdout(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a624eb",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "In our first implementation, we created a single test/train split.  Cross-validation is a more through way to perform model evaluation, at the cost of training time.\n",
    "\n",
    "Let's implement our model pipeline using the two functions we developed above with cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba1be0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles sqlite table: (8534, 9)\n",
      " train: (4551, 7) test: (2276, 7)\n",
      " train: (4551, 7) test: (2276, 7)\n",
      " train: (4552, 7) test: (2275, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data = create_dataset()\n",
    "dev, holdout = create_holdout(data)\n",
    "\n",
    "#  create 3 folds using stratified k fold\n",
    "splitter = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "for tr_idx, te_idx in splitter.split(dev, dev[\"newspaper_id\"]):\n",
    "    tr = dev.iloc[tr_idx]\n",
    "    te = dev.iloc[te_idx]\n",
    "    print(f\" train: {tr.shape} test: {te.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698425e8",
   "metadata": {},
   "source": [
    "Above we just create data - let's add in the code to train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff2168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles sqlite table: (8534, 9)\n",
      " 0 train: (4551, 7) test: (2276, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_20130/2317728112.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tr[\"target\"] = labels.fit_transform(tr[\"newspaper\"])\n",
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_20130/2317728112.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  te[\"target\"] = labels.transform(te[\"newspaper\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 scores: train: 0.1109646231597451 test: 0.11072056239015818\n",
      " 1 train: (4551, 7) test: (2276, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_20130/2317728112.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tr[\"target\"] = labels.fit_transform(tr[\"newspaper\"])\n",
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_20130/2317728112.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  te[\"target\"] = labels.transform(te[\"newspaper\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 scores: train: 0.1109646231597451 test: 0.11072056239015818\n",
      " 2 train: (4552, 7) test: (2275, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_20130/2317728112.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tr[\"target\"] = labels.fit_transform(tr[\"newspaper\"])\n",
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_20130/2317728112.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  te[\"target\"] = labels.transform(te[\"newspaper\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2 scores: train: 0.11072056239015818 test: 0.11120879120879121\n",
      "   train-score  test-score\n",
      "0     0.110965    0.110721\n",
      "1     0.110965    0.110721\n",
      "2     0.110721    0.111209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = create_dataset()\n",
    "dev, holdout = create_holdout(data)\n",
    "mdl = DummyClassifier()\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for idx, (tr_idx, te_idx) in enumerate(splitter.split(dev, dev[\"newspaper_id\"])):\n",
    "\n",
    "    mdl = clone(mdl)\n",
    "    tr = dev.iloc[tr_idx]\n",
    "    te = dev.iloc[te_idx]\n",
    "    print(f\" {idx} train: {tr.shape} test: {te.shape}\")\n",
    "\n",
    "    labels = LabelEncoder()\n",
    "    tr[\"target\"] = labels.fit_transform(tr[\"newspaper\"])\n",
    "    tfidf = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1, 2))\n",
    "    tr_features = tfidf.fit_transform(tr[\"body\"])\n",
    "\n",
    "    tr_score = accuracy_score(\n",
    "        tr[\"target\"], mdl.fit(tr_features, tr[\"target\"]).predict(tr_features)\n",
    "    )\n",
    "\n",
    "    te[\"target\"] = labels.transform(te[\"newspaper\"])\n",
    "    te_features = tfidf.transform(te[\"body\"])\n",
    "    te_score = accuracy_score(te[\"target\"], mdl.predict(te_features))\n",
    "    print(f\" {idx} scores: train: {tr_score} test: {te_score}\")\n",
    "    results.append({\"train-score\": tr_score, \"test-score\": te_score})\n",
    "\n",
    "print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8126276",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "articles sqlite table: (8534, 9)\n",
    " dev: (6827, 7) holdout: (1707, 7)\n",
    " 0 train: (4551, 7) test: (2276, 7)\n",
    " 0 scores: train: 0.11272247857613711 test: 0.11247803163444639\n",
    " 1 train: (4551, 7) test: (2276, 7)\n",
    " 1 scores: train: 0.11250274664908812 test: 0.11291739894551846\n",
    " 2 train: (4552, 7) test: (2275, 7)\n",
    " 2 scores: train: 0.11269771528998243 test: 0.11252747252747253\n",
    "   train-score  test-score\n",
    "0     0.112722    0.112478\n",
    "1     0.112503    0.112917\n",
    "2     0.112698    0.112527\n",
    "\n",
    "```\n",
    "\n",
    "## Iteration Three\n",
    "\n",
    "### Refactor\n",
    "\n",
    "Let's again take the chance to refactor our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4b73fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles sqlite table: (8534, 9)\n",
      "\n",
      "pipeline DummyClassifier():\n",
      " train: (4551, 7) test: (2276, 7)\n",
      " 0 scores: train: 0.1109646231597451 test: 0.11072056239015818\n",
      " train: (4551, 7) test: (2276, 7)\n",
      " 1 scores: train: 0.1109646231597451 test: 0.11072056239015818\n",
      " train: (4552, 7) test: (2275, 7)\n",
      " 2 scores: train: 0.11072056239015818 test: 0.11120879120879121\n",
      "train-score    0.110883\n",
      "test-score     0.110883\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train(mdl, data, encoders):\n",
    "    #  copy to avoid pandas setting with copy warning\n",
    "    data = data.copy()\n",
    "    newspapers = data[\"newspaper\"].copy()\n",
    "    data.loc[:, \"target\"] = encoders[\"target\"].fit_transform(newspapers)\n",
    "    features = encoders[\"tfidf\"].fit_transform(data[\"body\"])\n",
    "    return accuracy_score(\n",
    "        data[\"target\"], mdl.fit(features, data[\"target\"]).predict(features)\n",
    "    )\n",
    "\n",
    "\n",
    "def test(mdl, data, encoders):\n",
    "    #  copy to avoid pandas setting with copy warning\n",
    "    data = data.copy()\n",
    "    newspapers = data[\"newspaper\"].copy()\n",
    "    data.loc[:, \"target\"] = encoders[\"target\"].transform(newspapers)\n",
    "    features = encoders[\"tfidf\"].transform(data[\"body\"])\n",
    "    return accuracy_score(data[\"target\"], mdl.predict(features))\n",
    "\n",
    "\n",
    "def pipeline(mdl, data):\n",
    "    print(f\"\\npipeline {mdl}:\")\n",
    "\n",
    "    splitter = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    results = []\n",
    "    for idx, (tr_idx, te_idx) in enumerate(splitter.split(data, data[\"newspaper_id\"])):\n",
    "        encoders = {\n",
    "            \"target\": LabelEncoder(),\n",
    "            \"tfidf\": TfidfVectorizer(\n",
    "                min_df=5, max_df=0.9, max_features=1000, ngram_range=(1, 2)\n",
    "            ),\n",
    "        }\n",
    "        mdl = clone(mdl)\n",
    "        tr = data.iloc[tr_idx]\n",
    "        te = data.iloc[te_idx]\n",
    "        print(f\" train: {tr.shape} test: {te.shape}\")\n",
    "\n",
    "        tr_score = train(mdl, tr, encoders)\n",
    "        te_score = test(mdl, te, encoders)\n",
    "        print(f\" {idx} scores: train: {tr_score} test: {te_score}\")\n",
    "        results.append({\"train-score\": tr_score, \"test-score\": te_score})\n",
    "\n",
    "    return pd.DataFrame(results).mean()\n",
    "\n",
    "dev = create_dataset()\n",
    "dev, holdout = create_holdout(dev)\n",
    "mdl = DummyClassifier()\n",
    "results = pipeline(mdl, dev)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027eb76c",
   "metadata": {},
   "source": [
    "```\n",
    "articles sqlite table: (8534, 9)\n",
    "\n",
    "pipeline DummyClassifier():\n",
    " train: (4551, 7) test: (2276, 7)\n",
    " 0 scores: train: 0.1109646231597451 test: 0.11072056239015818\n",
    " train: (4551, 7) test: (2276, 7)\n",
    " 1 scores: train: 0.1109646231597451 test: 0.11072056239015818\n",
    " train: (4552, 7) test: (2275, 7)\n",
    " 2 scores: train: 0.11072056239015818 test: 0.11120879120879121\n",
    "\n",
    "train-score    0.110883\n",
    "test-score     0.110883\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "### Add Hyperparameter Tuning with a Grid Search\n",
    "\n",
    "Let's pick some hyperparameters to tune and add a grid search to our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09525d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params = {\n",
    "    \"min_df\": [1, 5, 10],\n",
    "    \"max_df\": [0.5, 0.9],\n",
    "    \"ngram_range\": [(1, 1), (2, 2)],\n",
    "    \"n_estimators\": [100, 500],\n",
    "    \"max_depth\": [None, 5],\n",
    "    \"max_features_tfidf\": [100, 1000],\n",
    "}\n",
    "grid = ParameterGrid(params)\n",
    "print(len(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353748d0",
   "metadata": {},
   "source": [
    "```\n",
    "96\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7762b",
   "metadata": {},
   "source": [
    "Now let's integrate these hyperparameters into our pipeline with a random forest - this requires adding these arguments to our `pipeline` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aed9d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(mdl, data, hyperparameters):\n",
    "    print(f\"pipeline {mdl}:\")\n",
    "\n",
    "    splitter = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    results = []\n",
    "    for idx, (tr_idx, te_idx) in enumerate(splitter.split(data, data[\"newspaper_id\"])):\n",
    "        encoders = {\n",
    "            \"target\": LabelEncoder(),\n",
    "            \"tfidf\": TfidfVectorizer(\n",
    "                min_df=hyperparameters[\"min_df\"],\n",
    "                max_df=hyperparameters[\"max_df\"],\n",
    "                max_features=hyperparameters[\"max_features_tfidf\"],\n",
    "                ngram_range=hyperparameters[\"ngram_range\"],\n",
    "            ),\n",
    "        }\n",
    "        mdl = clone(mdl)\n",
    "        tr = data.iloc[tr_idx]\n",
    "        te = data.iloc[te_idx]\n",
    "        print(f\" train: {tr.shape} test: {te.shape}\")\n",
    "\n",
    "        tr_score = train(mdl, tr, encoders)\n",
    "        te_score = test(mdl, te, encoders)\n",
    "        print(f\" fold {idx} scores: train: {tr_score} test: {te_score}\")\n",
    "        results.append({\"train-score\": tr_score, \"test-score\": te_score})\n",
    "    return pd.DataFrame(results).mean().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1bd06",
   "metadata": {},
   "source": [
    "Now let's use this hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc274de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grid params 0 of 96:\n",
      "pipeline RandomForestClassifier():\n",
      " train: (3413, 7) test: (3414, 7)\n",
      " fold 0 scores: train: 0.998828010547905 test: 0.5509666080843585\n",
      " train: (3414, 7) test: (3413, 7)\n",
      " fold 1 scores: train: 0.9997070884592852 test: 0.6024025783767946\n",
      "\n",
      "grid params 1 of 96:\n",
      "pipeline RandomForestClassifier():\n",
      " train: (3413, 7) test: (3414, 7)\n"
     ]
    }
   ],
   "source": [
    "grid_results = []\n",
    "for idx, params in enumerate(grid):\n",
    "    mdl = RandomForestClassifier(\n",
    "        n_estimators=params[\"n_estimators\"], max_depth=params[\"max_depth\"]\n",
    "    )\n",
    "    print(f\"\\ngrid params {idx} of {len(grid)}:\")\n",
    "    result = pipeline(mdl, dev.copy(), params)\n",
    "    grid_results.append({\n",
    "      **params,\n",
    "      **result,\n",
    "      \"run_id\": idx\n",
    "    })\n",
    "    df = pd.DataFrame(grid_results)\n",
    "    df.to_parquet(home / \"grid.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e165b",
   "metadata": {},
   "source": [
    "```\n",
    "grid params 0 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.998828010547905 test: 0.5439367311072056\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9997070884592852 test: 0.6032815704658658\n",
    "\n",
    "grid params 1 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9970700263697627 test: 0.515817223198594\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.997070884592853 test: 0.527395253442719\n",
    "\n",
    "grid params 2 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.998828010547905 test: 0.5653192735793791\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9997070884592852 test: 0.6126574860826253\n",
    "\n",
    "grid params 3 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9970700263697627 test: 0.531634446397188\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.997070884592853 test: 0.5411661295048344\n",
    "\n",
    "grid params 4 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.998828010547905 test: 0.5456942003514939\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9997070884592852 test: 0.6006445941986522\n",
    "\n",
    "grid params 5 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9970700263697627 test: 0.517867603983597\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.997070884592853 test: 0.5265162613536478\n",
    "\n",
    "grid params 6 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.998828010547905 test: 0.5650263620386643\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9997070884592852 test: 0.6164664518019338\n",
    "\n",
    "grid params 7 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9970700263697627 test: 0.5333919156414763\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.997070884592853 test: 0.5402871374157633\n",
    "\n",
    "grid params 8 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.998828010547905 test: 0.5509666080843585\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9997070884592852 test: 0.595370641664225\n",
    "\n",
    "grid params 9 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9970700263697627 test: 0.5175746924428822\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.997070884592853 test: 0.5297392323469089\n",
    "\n",
    "grid params 10 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.998828010547905 test: 0.5656121851200937\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9997070884592852 test: 0.6088485203633167\n",
    "\n",
    "grid params 11 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9970700263697627 test: 0.525776215582894\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.997070884592853 test: 0.5391151479636683\n",
    "\n",
    "grid params 12 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7656707674282367\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7808379724582479\n",
    "\n",
    "grid params 13 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7536613942589337\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7562261939642543\n",
    "\n",
    "grid params 14 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7820738137082601\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7896278933489599\n",
    "\n",
    "grid params 15 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7612770943175161\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7723410489305597\n",
    "\n",
    "grid params 16 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7721148213239601\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7746850278347495\n",
    "\n",
    "grid params 17 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7551259519625073\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.760914151772634\n",
    "\n",
    "grid params 18 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7867603983596954\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7869909170817463\n",
    "\n",
    "grid params 19 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7650849443468073\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7650161148549663\n",
    "\n",
    "grid params 20 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7674282366725249\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7699970700263697\n",
    "\n",
    "grid params 21 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7480960749853545\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7606211544096103\n",
    "\n",
    "grid params 22 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7888107791446983\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7820099619103428\n",
    "\n",
    "grid params 23 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7644991212653779\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7656021095810138\n",
    "\n",
    "grid params 24 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.46367896895137667\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.4825666569000879\n",
    "\n",
    "grid params 25 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9985350131848814 test: 0.4938488576449912\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9994141769185706 test: 0.5303252270729564\n",
    "\n",
    "grid params 26 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.4953134153485647\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.5139173747436273\n",
    "\n",
    "grid params 27 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9985350131848814 test: 0.5146455770357352\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9994141769185706 test: 0.5443891004980955\n",
    "\n",
    "grid params 28 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.46953719976567077\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.48901259888661003\n",
    "\n",
    "grid params 29 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9985350131848814 test: 0.4991212653778559\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9994141769185706 test: 0.5285672428948139\n",
    "\n",
    "grid params 30 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.4956063268892794\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.5095224142982713\n",
    "\n",
    "grid params 31 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9985350131848814 test: 0.520796719390744\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9994141769185706 test: 0.5399941400527395\n",
    "\n",
    "grid params 32 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.471294669009959\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.4796366832698506\n",
    "\n",
    "grid params 33 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9985350131848814 test: 0.5002929115407148\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9994141769185706 test: 0.5282742455317903\n",
    "\n",
    "grid params 34 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.4944346807264206\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.5183123351889833\n",
    "\n",
    "grid params 35 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.9985350131848814 test: 0.5219683655536028\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.9994141769185706 test: 0.5470260767653091\n",
    "\n",
    "grid params 36 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7662565905096661\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7764430120128919\n",
    "\n",
    "grid params 37 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7480960749853545\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7562261939642543\n",
    "\n",
    "grid params 38 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.784124194493263\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7773220041019631\n",
    "\n",
    "grid params 39 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7565905096660809\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.76530911221799\n",
    "\n",
    "grid params 40 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7568834212067955\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.766481101670085\n",
    "\n",
    "grid params 41 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7495606326889279\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7503662467037797\n",
    "\n",
    "grid params 42 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7817809021675454\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7767360093759156\n",
    "\n",
    "grid params 43 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7580550673696543\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7635511280398476\n",
    "\n",
    "grid params 44 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7653778558875219\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7644301201289189\n",
    "\n",
    "grid params 45 of 96:\n",
    "pipeline RandomForestClassifier():\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7533684827182191\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7453852915323762\n",
    "\n",
    "grid params 46 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7782659636789689\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.778493993554058\n",
    "\n",
    "grid params 47 of 96:\n",
    "pipeline RandomForestClassifier(n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 1.0 test: 0.7589338019917985\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 1.0 test: 0.7615001464986815\n",
    "\n",
    "grid params 48 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.543803105772048 test: 0.46104276508494435\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5641476274165202 test: 0.5010254907705831\n",
    "\n",
    "grid params 49 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5092294169352476 test: 0.44141769185705915\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5026362038664324 test: 0.46205684148842663\n",
    "\n",
    "grid params 50 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5364781716964547 test: 0.4513766842413591\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5767428236672525 test: 0.5086434222092001\n",
    "\n",
    "grid params 51 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5162613536478172 test: 0.45166959578207383\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5041007615700058 test: 0.46088485203633167\n",
    "\n",
    "grid params 52 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5367711690594784 test: 0.45547744581136496\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5817223198594025 test: 0.5092294169352476\n",
    "\n",
    "grid params 53 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5092294169352476 test: 0.4361452841241945\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5117164616285882 test: 0.46352182830354527\n",
    "\n",
    "grid params 54 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5440961031350717 test: 0.45547744581136496\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5749853544229643 test: 0.5068854380310577\n",
    "\n",
    "grid params 55 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5159683562847934 test: 0.4507908611599297\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5087873462214412 test: 0.4696747729270437\n",
    "\n",
    "grid params 56 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5338411954292411 test: 0.45489162272993555\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5758640890451083 test: 0.5016114854966305\n",
    "\n",
    "grid params 57 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5162613536478172 test: 0.45254833040421794\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.49502050380785 test: 0.45619689422795195\n",
    "\n",
    "grid params 58 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5476120714913566 test: 0.45694200351493847\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5732278851786761 test: 0.5068854380310577\n",
    "\n",
    "grid params 59 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5177263404629359 test: 0.4502050380785003\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.4997070884592853 test: 0.46000585994726045\n",
    "\n",
    "grid params 60 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6229123937884559 test: 0.5928529584065613\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.635618043350908 test: 0.6196894227951948\n",
    "\n",
    "grid params 61 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5039554644008204 test: 0.4967779730521383\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5263620386643234 test: 0.5048344564898916\n",
    "\n",
    "grid params 62 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6243773806035746 test: 0.6028119507908611\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6244874048037493 test: 0.6138294755347202\n",
    "\n",
    "grid params 63 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4992675065924407 test: 0.5014645577035736\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5275336848271822 test: 0.5062994433050102\n",
    "\n",
    "grid params 64 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6191034280691474 test: 0.5987111892208553\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6250732278851787 test: 0.6106065045414591\n",
    "\n",
    "grid params 65 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4895985936126575 test: 0.4874048037492677\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5087873462214412 test: 0.48842660416056255\n",
    "\n",
    "grid params 66 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6223263990624084 test: 0.6010544815465729\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6294669009958992 test: 0.6144154702607677\n",
    "\n",
    "grid params 67 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4939935540580135 test: 0.4947275922671353\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5202108963093146 test: 0.5001464986815118\n",
    "\n",
    "grid params 68 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6276003515968356 test: 0.6028119507908611\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6303456356180434 test: 0.6158804570758863\n",
    "\n",
    "grid params 69 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4960445355991796 test: 0.4976567076742824\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5304628002343292 test: 0.51098740111339\n",
    "\n",
    "grid params 70 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6255493700556695 test: 0.6051552431165788\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6280023432923257 test: 0.6114854966305303\n",
    "\n",
    "grid params 71 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4939935540580135 test: 0.4953134153485647\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5202108963093146 test: 0.4986815118663932\n",
    "\n",
    "grid params 72 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.476999707002637 test: 0.40392501464557706\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.46748681898066785 test: 0.3964254321711105\n",
    "\n",
    "grid params 73 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4881336067975388 test: 0.42618629173989453\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.4876977152899824 test: 0.45531790213888074\n",
    "\n",
    "grid params 74 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.47729270436566074 test: 0.4065612185120094\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.4710017574692443 test: 0.3975974216232054\n",
    "\n",
    "grid params 75 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4887196015235863 test: 0.4273579379027534\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.4956063268892794 test: 0.45531790213888074\n",
    "\n",
    "grid params 76 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.47582771755054204 test: 0.39777387229056826\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.46309314586994726 test: 0.38997949018458833\n",
    "\n",
    "grid params 77 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.48725461470846765 test: 0.4270650263620387\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.4938488576449912 test: 0.45678288895399943\n",
    "\n",
    "grid params 78 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4761207149135658 test: 0.4091974223784417\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.47656707674282367 test: 0.4028713741576326\n",
    "\n",
    "grid params 79 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4881336067975388 test: 0.4270650263620387\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.4838898652606913 test: 0.45414591268678584\n",
    "\n",
    "grid params 80 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.46674479929680635 test: 0.3992384299941418\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.46133567662565905 test: 0.3917374743627307\n",
    "\n",
    "grid params 81 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.4925285672428948 test: 0.4308728763913298\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.4938488576449912 test: 0.45268092587166714\n",
    "\n",
    "grid params 82 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.47846469381775564 test: 0.4124194493263035\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.47539543057996486 test: 0.40140638734251394\n",
    "\n",
    "grid params 83 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.48842660416056255 test: 0.4288224956063269\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.484182776801406 test: 0.4532669205977146\n",
    "\n",
    "grid params 84 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6138294755347202 test: 0.5978324545987111\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6262448740480375 test: 0.6182244359800761\n",
    "\n",
    "grid params 85 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5517140345736888 test: 0.5442296426479203\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5656121851200937 test: 0.5470260767653091\n",
    "\n",
    "grid params 86 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6229123937884559 test: 0.6036906854130053\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6236086701816052 test: 0.6111924992675066\n",
    "\n",
    "grid params 87 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5514210372106652 test: 0.5468658465143527\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5612185120093731 test: 0.5399941400527395\n",
    "\n",
    "grid params 88 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6220334016993847 test: 0.6031048623315759\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6203866432337434 test: 0.6073835335481981\n",
    "\n",
    "grid params 89 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5411661295048344 test: 0.5392501464557704\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5852372583479789 test: 0.5719308526223263\n",
    "\n",
    "grid params 90 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6276003515968356 test: 0.6031048623315759\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.616871704745167 test: 0.6044535599179608\n",
    "\n",
    "grid params 91 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5487840609434516 test: 0.5448154657293497\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5796719390743995 test: 0.5599179607383533\n",
    "\n",
    "grid params 92 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.6246703779665983 test: 0.6060339777387229\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6285881663737551 test: 0.6147084676237914\n",
    "\n",
    "grid params 93 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5511280398476414 test: 0.5459871118922085\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5828939660222613 test: 0.5648989159097568\n",
    "\n",
    "grid params 94 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.624963375329622 test: 0.6013473930872877\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.6183362624487405 test: 0.604160562554937\n",
    "\n",
    "grid params 95 of 96:\n",
    "pipeline RandomForestClassifier(max_depth=5, n_estimators=500):\n",
    " train: (3413, 7) test: (3414, 7)\n",
    " fold 0 scores: train: 0.5432171110460006 test: 0.5424721734036321\n",
    " train: (3414, 7) test: (3413, 7)\n",
    " fold 1 scores: train: 0.5796719390743995 test: 0.5637269264576619\n",
    "\n",
    "```\n",
    "\n",
    "### Select & Train on Best Params \n",
    "\n",
    "Now our grid search is over, we can select the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ea2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = pd.read_parquet(home / \"grid.parquet\")\n",
    "\n",
    "#  select best test-score row\n",
    "best_fold = grid.sort_values(\"test-score\", ascending=False).iloc[0]\n",
    "\n",
    "best_fold = best_fold.to_dict()\n",
    "print(best_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c1728",
   "metadata": {},
   "source": [
    "```\n",
    "{'max_depth': nan, 'max_df': 0.5, 'max_features_tfidf': 1000, 'min_df': 5, 'n_estimators': 500, 'ngram_range': array([1, 1]), 'train-score': 1.0, 'test-score': 0.7868756577207208, 'run_id': 18}\n",
    "```\n",
    "\n",
    "We can now use our `test` and `train` functions again with our final, best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa376994",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataset()\n",
    "tr, ho = create_holdout(data)\n",
    "\n",
    "if np.isnan(best_fold['max_depth']):\n",
    "    best_fold['max_depth'] = None\n",
    "else:\n",
    "    best_fold['max_depth'] = int(best_fold['max_depth'])\n",
    "    \n",
    "print(f\"best_params: {best_fold}\")\n",
    "mdl = RandomForestClassifier(\n",
    "    n_estimators=best_fold[\"n_estimators\"], max_depth=best_fold[\"max_depth\"] \n",
    ")\n",
    "encoders = {\n",
    "    \"target\": LabelEncoder(),\n",
    "    \"tfidf\": TfidfVectorizer(\n",
    "        min_df=best_fold[\"min_df\"],\n",
    "        max_df=best_fold[\"max_df\"],\n",
    "        max_features=best_fold[\"max_features_tfidf\"],\n",
    "        ngram_range=tuple(best_fold[\"ngram_range\"]),\n",
    "    ),\n",
    "}\n",
    "\n",
    "tr_score = train(mdl, tr, encoders)\n",
    "te_score = test(mdl, ho, encoders)\n",
    "print(f\" scores train: {tr_score} test: {te_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0bf4e",
   "metadata": {},
   "source": [
    "```\n",
    "articles sqlite table: (8534, 9)\n",
    "best_params: {'max_depth': None, 'max_df': 0.5, 'max_features_tfidf': 1000, 'min_df': 5, 'n_estimators': 500, 'ngram_range': array([1, 1]), 'train-score': 1.0, 'test-score': 0.7868756577207208, 'run_id': 18}\n",
    " scores train: 1.0 test: 0.8131224370240188\n",
    "```\n",
    "\n",
    "### Train Final Model\n",
    "\n",
    "We have our final estimate of model performance - with an expected performance of predicting the newspaper correctly 80% of the time.\n",
    "\n",
    "Our final model that would go into production should be trained on as much data as possible - the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = create_dataset()\n",
    "mdl = RandomForestClassifier(\n",
    "    n_estimators=best_fold[\"n_estimators\"], max_depth=best_fold[\"max_depth\"]\n",
    ")\n",
    "encoders = {\n",
    "    \"target\": LabelEncoder(),\n",
    "    \"tfidf\": TfidfVectorizer(\n",
    "        min_df=best_fold[\"min_df\"],\n",
    "        max_df=best_fold[\"max_df\"],\n",
    "        max_features=best_fold[\"max_features_tfidf\"],\n",
    "        ngram_range=tuple(best_fold[\"ngram_range\"]),\n",
    "    ),\n",
    "}\n",
    "tr_score = train(mdl, tr, encoders)\n",
    "print(f\" scores train: {tr_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739544e",
   "metadata": {},
   "source": [
    "```\n",
    "articles sqlite table: (8534, 9)\n",
    " scores train: 1.0\n",
    "```\n",
    "\n",
    "We are left with only as estimate of the performance on the training set - our final model is trained on all the data.  We still expect this model to perform with around 80% accuracy."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
