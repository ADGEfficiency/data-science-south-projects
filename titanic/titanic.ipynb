{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722e4a35",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "The Titanic dataset is a classic in machine learning.\n",
    "\n",
    "The data for this project comes from [Kaggle](https://www.kaggle.com/competitions/titanic/data) - you can explore & learn from [other people's solutions](https://www.kaggle.com/competitions/titanic/code) as well.\n",
    "\n",
    "## Project Goals\n",
    "\n",
    "Predict whether a passenger survived the Titanic disaster. This is a classification problem.\n",
    "\n",
    "You can find the Jupyter Notebook for this lesson here - run it on Binder here.\n",
    "\n",
    "## Project Plan\n",
    "\n",
    "In this project, we will:\n",
    "\n",
    "- explore the Titanic dataset using pandas,\n",
    "- develop first pipeline to make predictions with a baseline & random forest,\n",
    "- develop a second pipeline to also use logistic regression and do grid searching.\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Let's start by loading our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4160645-5cd8-4c1a-ab04-f5853dbf54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f75d7f",
   "metadata": {},
   "source": [
    "One option here is to separate out a holdout set before we continue with any further data analysis.  For this project, we will continue with the entire dataset.\n",
    "\n",
    "### How many Rows and Columns Are There?\n",
    "\n",
    "Our dataset has 891 rows and 12 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4ec47d-9113-4797-b6ea-7afb41d29b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15081f",
   "metadata": {},
   "source": [
    "### What Does The Data Look Like?\n",
    "\n",
    "We can take a look at the raw data directly with `head`, `tail` and `sample`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b73f58b-56f6-444c-b81b-5ab17ec1a94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked\n",
       "0            1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500   NaN        S\n",
       "1            2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C\n",
       "2            3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S\n",
       "3            4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S\n",
       "4            5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500   NaN        S"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3144ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.00</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name     Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked\n",
       "886          887         0       2                     Montvila, Rev. Juozas    male  27.0      0      0      211536  13.00   NaN        S\n",
       "887          888         1       1              Graham, Miss. Margaret Edith  female  19.0      0      0      112053  30.00   B42        S\n",
       "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2  W./C. 6607  23.45   NaN        S\n",
       "889          890         1       1                     Behr, Mr. Karl Howell    male  26.0      0      0      111369  30.00  C148        C\n",
       "890          891         0       3                       Dooley, Mr. Patrick    male  32.0      0      0      370376   7.75   NaN        Q"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db84dd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Meyer, Mr. Edgar Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17604</td>\n",
       "      <td>82.1708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Gilnagh, Miss. Katherine \"Katie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35851</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>577</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Garside, Miss. Ethel</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243880</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moussa, Mrs. (Mantoura Boulos)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2626</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch    Ticket     Fare Cabin Embarked\n",
       "34            35         0       1                            Meyer, Mr. Edgar Joseph    male  28.0      1      0  PC 17604  82.1708   NaN        C\n",
       "156          157         1       3                   Gilnagh, Miss. Katherine \"Katie\"  female  16.0      0      0     35851   7.7333   NaN        Q\n",
       "576          577         1       2                               Garside, Miss. Ethel  female  34.0      0      0    243880  13.0000   NaN        S\n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0  PC 17599  71.2833   C85        C\n",
       "367          368         1       3                     Moussa, Mrs. (Mantoura Boulos)  female   NaN      0      0      2626   7.2292   NaN        C"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c019604",
   "metadata": {},
   "source": [
    "### Exploring the Features\n",
    "\n",
    "Most of our features are self-explanatory - some of the less obvious features are explored below.  [The dataset is also documented on Kaggle](https://www.kaggle.com/competitions/titanic/data).\n",
    "\n",
    "`siBsp` describes family relations - it is the sum of the total siblings or spouses of that passenger on the ship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae081d8c-99d7-48f7-b76a-eacd8d2f3c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9dc66a",
   "metadata": {},
   "source": [
    "`Parch` describes family relations for parents and children:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1eb81f8-fef9-456c-8721-103b566d5762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    678\n",
       "1    118\n",
       "2     80\n",
       "5      5\n",
       "3      5\n",
       "4      4\n",
       "6      1\n",
       "Name: Parch, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44026df7",
   "metadata": {},
   "source": [
    "`Ticket` is the ticket number - multiple passengers can be on the same ticket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c438a7c-5d35-4b44-b129-cbdf13b5ad8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312993      1\n",
       "349234      1\n",
       "A/5 3540    1\n",
       "3101264     1\n",
       "PC 17595    1\n",
       "           ..\n",
       "CA 2144     6\n",
       "3101295     6\n",
       "1601        7\n",
       "CA. 2343    7\n",
       "347082      7\n",
       "Name: Ticket, Length: 681, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Ticket'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5317116",
   "metadata": {},
   "source": [
    "`Fare` is the cost of a ticket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c040be0-2fe0-4bac-a886-3d02b0999d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      32.204208\n",
       "std       49.693429\n",
       "min        0.000000\n",
       "25%        7.910400\n",
       "50%       14.454200\n",
       "75%       31.000000\n",
       "max      512.329200\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Fare'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f256e",
   "metadata": {},
   "source": [
    "`Cabin` is the cabin number - multiple passengers can be in the same cabin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb09685-5bda-44e9-b2dd-5bd8dc3d2cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B102               1\n",
       "C99                1\n",
       "B94                1\n",
       "C87                1\n",
       "D15                1\n",
       "A31                1\n",
       "B80                1\n",
       "B86                1\n",
       "B4                 1\n",
       "C49                1\n",
       "A7                 1\n",
       "B19                1\n",
       "D47                1\n",
       "D7                 1\n",
       "F E69              1\n",
       "A32                1\n",
       "C95                1\n",
       "E10                1\n",
       "B39                1\n",
       "B82 B84            1\n",
       "D6                 1\n",
       "B3                 1\n",
       "F38                1\n",
       "E77                1\n",
       "D11                1\n",
       "D30                1\n",
       "C46                1\n",
       "D45                1\n",
       "B101               1\n",
       "B38                1\n",
       "C45                1\n",
       "C90                1\n",
       "C62 C64            1\n",
       "F G63              1\n",
       "C110               1\n",
       "A36                1\n",
       "D10 D12            1\n",
       "E31                1\n",
       "C111               1\n",
       "C104               1\n",
       "C82                1\n",
       "C106               1\n",
       "E50                1\n",
       "D37                1\n",
       "E38                1\n",
       "C128               1\n",
       "E40                1\n",
       "C91                1\n",
       "C32                1\n",
       "E34                1\n",
       "C7                 1\n",
       "C54                1\n",
       "T                  1\n",
       "D21                1\n",
       "E12                1\n",
       "E63                1\n",
       "B30                1\n",
       "B78                1\n",
       "A6                 1\n",
       "D56                1\n",
       "C103               1\n",
       "E46                1\n",
       "C118               1\n",
       "A19                1\n",
       "B73                1\n",
       "A34                1\n",
       "D46                1\n",
       "B79                1\n",
       "C30                1\n",
       "B37                1\n",
       "A14                1\n",
       "A5                 1\n",
       "E36                1\n",
       "C148               1\n",
       "E49                1\n",
       "B69                1\n",
       "C70                1\n",
       "E58                1\n",
       "A16                1\n",
       "D19                1\n",
       "D48                1\n",
       "A26                1\n",
       "B50                1\n",
       "A20                1\n",
       "C101               1\n",
       "A10                1\n",
       "A23                1\n",
       "C86                1\n",
       "D9                 1\n",
       "E68                1\n",
       "D28                1\n",
       "E17                1\n",
       "C47                1\n",
       "C50                1\n",
       "A24                1\n",
       "D49                1\n",
       "B71                1\n",
       "C85                1\n",
       "D50                1\n",
       "B41                1\n",
       "B42                1\n",
       "C65                2\n",
       "B49                2\n",
       "E24                2\n",
       "B18                2\n",
       "B35                2\n",
       "E67                2\n",
       "C125               2\n",
       "D36                2\n",
       "E44                2\n",
       "E121               2\n",
       "C123               2\n",
       "B77                2\n",
       "E8                 2\n",
       "C93                2\n",
       "C78                2\n",
       "B20                2\n",
       "D35                2\n",
       "B5                 2\n",
       "C68                2\n",
       "C126               2\n",
       "E33                2\n",
       "C2                 2\n",
       "C92                2\n",
       "B22                2\n",
       "B57 B59 B63 B66    2\n",
       "E25                2\n",
       "C83                2\n",
       "B28                2\n",
       "D17                2\n",
       "D20                2\n",
       "D33                2\n",
       "C52                2\n",
       "B58 B60            2\n",
       "F G73              2\n",
       "C124               2\n",
       "F4                 2\n",
       "B51 B53 B55        2\n",
       "D26                2\n",
       "C22 C26            3\n",
       "F33                3\n",
       "D                  3\n",
       "E101               3\n",
       "F2                 3\n",
       "C23 C25 C27        4\n",
       "G6                 4\n",
       "B96 B98            4\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Cabin'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aeb794",
   "metadata": {},
   "source": [
    "`Embarked` is the port of embarkation - where the passenger boarded the Titanic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90331e77-fa1a-4119-b40c-2e85981a77a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f84b3",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "We can check for missing values by taking the `sum` across the boolean array returned by `pd.DataFrame.isnull()`.\n",
    "\n",
    "We can see we have missing values in `Age` and `Cabin`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c975b2-3362-4812-80b5-38980ec3679b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe3e75fa-c811-4d65-8baf-2aaa560a237e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[~data['Cabin'].isnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed193d-d812-44b6-bf3f-d0104d6cbd76",
   "metadata": {},
   "source": [
    "## First Pipeline - Predict with a Baseline Model & Random Forest\n",
    "\n",
    "For our first pipeline, we will:\n",
    "\n",
    "1. test train split,\n",
    "2. data cleaning / feature eng as needed (little as possible),\n",
    "3. baseline model (dummy classification),\n",
    "4. random forest.\n",
    "\n",
    "The mindset for this first iteration is trying to figure out whether this problem is worth spending more time on.\n",
    "\n",
    "### Test Train Split\n",
    "\n",
    "First thing we do is split our data - creating a train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d40b635-3815-4cc0-92b1-252a7689073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(757, 12) (134, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.15)\n",
    "assert train.shape[0] > test.shape[0]\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a06ac",
   "metadata": {},
   "source": [
    "As we discovered during EDA, our data has null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28e04245-852c-43d5-9e87-e43c3f39cf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            156\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          589\n",
       "Embarked         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9991f7c",
   "metadata": {},
   "source": [
    "```\n",
    "PassengerId      0\n",
    "Survived         0\n",
    "Pclass           0\n",
    "Name             0\n",
    "Sex              0\n",
    "Age            153\n",
    "SibSp            0\n",
    "Parch            0\n",
    "Ticket           0\n",
    "Fare             0\n",
    "Cabin          588\n",
    "Embarked         2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### Drop Rows Where Age & Embarked Are Missing\n",
    "\n",
    "We can deal with our missing values in the `Age` and `Embarked` columns by dropping the rows.  \n",
    "\n",
    "We choose to drop rows here as we will not lose too much data when doing so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77fa3057-3805-4e60-a606-d07c3f664285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          450\n",
      "Embarked         0\n",
      "dtype: int64 (600, 12)\n"
     ]
    }
   ],
   "source": [
    "train = train[~train['Age'].isnull()]\n",
    "train = train[~train['Embarked'].isnull()]\n",
    "print(train.isnull().sum(), train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e975a7",
   "metadata": {},
   "source": [
    "```\n",
    "PassengerId      0\n",
    "Survived         0\n",
    "Pclass           0\n",
    "Name             0\n",
    "Sex              0\n",
    "Age              0\n",
    "SibSp            0\n",
    "Parch            0\n",
    "Ticket           0\n",
    "Fare             0\n",
    "Cabin          446\n",
    "Embarked         0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "### Drop Entire Cabin Column\n",
    "\n",
    "We have so many missing values in the `Cabin` column that it makes sense to drop the entire column - if we dropped rows, we would lose too much data, so we drop the column instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e9566fc-4867-4fff-bda0-d87d2dc00563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 11)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop('Cabin', axis=1)\n",
    "assert train.isnull().sum().sum() == 0\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a19a426",
   "metadata": {},
   "source": [
    "```\n",
    "(607, 11)\n",
    "```\n",
    "\n",
    "### Encode Categorical Variables by Dropping\n",
    "\n",
    "Our feature engineering for categorical variables here is to remove them - in a later iteration, we would integrate these as features using either one-hot encoding or label encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ead1046-eb76-4b02-80d9-fae9baf569ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name', 'Sex', 'Embarked', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e0e555",
   "metadata": {},
   "source": [
    "### Drop No Information PassengerId\n",
    "\n",
    "`PassengerId` is a unique identifier for each passenger - it does not provide any information about the passenger, so we can drop it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f63255a3-062a-4454-ac72-85460a3ffe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f652e3",
   "metadata": {},
   "source": [
    "### Create Target\n",
    "\n",
    "Our target engineering involves separating the `Survived` column into a separate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc27e034-883d-49f5-8a8c-cb968fcac067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1) (600, 5)\n"
     ]
    }
   ],
   "source": [
    "target = train['Survived'].to_frame()\n",
    "features = train.drop('Survived', axis=1)\n",
    "print(target.shape, features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a8b9f",
   "metadata": {},
   "source": [
    "```\n",
    "(607, 1) (607, 5)\n",
    "```\n",
    "\n",
    "### Dummy Classifier\n",
    "\n",
    "At this point we have both our target and our features - let's train our baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4b38f55-8b62-472b-b82c-bde3fd7243dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "mdl = DummyClassifier()\n",
    "mdl = mdl.fit(features, target)\n",
    "predictions = mdl.predict(features)\n",
    "print(mdl.score(features, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94002953",
   "metadata": {},
   "source": [
    "```\n",
    "0.5831960461285008\n",
    "```\n",
    "\n",
    "We use the `.score()` method to get the accuracy of our model - the `.score` method is different for different models.  scikit-learn has [metrics for many machine learning problems](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "### Bring It All Together\n",
    "\n",
    "We can bring together all the code for our first iteration into a single script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b59ce131-e86f-4e64-b45c-1e29dc7b15a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6085526315789473\n",
      "0.5192307692307693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pipeline(train):\n",
    "    train = train[~train['Age'].isnull()]\n",
    "    train = train[~train['Embarked'].isnull()]\n",
    "    train = train.drop('Cabin', axis=1)\n",
    "    train = train.drop(['Name', 'Sex', 'Embarked', 'Ticket'], axis=1)\n",
    "    train = train.drop('PassengerId', axis=1)\n",
    "    target = train['Survived'].to_frame()\n",
    "    features = train.drop('Survived', axis=1)\n",
    "    return features, target\n",
    "\n",
    "data = pd.read_csv('data/train.csv')\n",
    "train, test = train_test_split(data, test_size=0.15)\n",
    "assert train.shape[0] > test.shape[0]\n",
    "\n",
    "features_tr, target_tr = pipeline(train)\n",
    "features_te, target_te = pipeline(test)\n",
    "\n",
    "mdl = DummyClassifier()\n",
    "mdl = mdl.fit(features_tr, target_tr)\n",
    "print(mdl.score(features_tr, target_tr))\n",
    "print(mdl.score(features_te, target_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41236007",
   "metadata": {},
   "source": [
    "We end up with a 65% accuracy for our baseline model.\n",
    "\n",
    "## Add Random Forest\n",
    "\n",
    "Now let's add a random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a0a0060-f760-41e8-90bf-80257c73903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975328947368421\n",
      "0.7692307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_19427/1612947531.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  mdl = mdl.fit(features_tr, target_tr)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mdl = RandomForestClassifier()\n",
    "mdl = mdl.fit(features_tr, target_tr)\n",
    "print(mdl.score(features_tr, target_tr))\n",
    "print(mdl.score(features_te, target_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13d5e3",
   "metadata": {},
   "source": [
    "We end up with a 68% accuracy for our baseline model on the test set, but with almost 100% accuracy on the training set.\n",
    "\n",
    "This suggests that if we can reduce this overfitting, we perhaps can improve our generalization.\n",
    "\n",
    "### Final First Pipeline\n",
    "\n",
    "Here is our complete final pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8024b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_19427/2828666670.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  mdl = mdl.fit(features_tr, target_tr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5963756177924218\n",
      "0.5904761904761905\n",
      "0.9736408566721582\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def pipeline(train):\n",
    "    train = train[~train['Age'].isnull()]\n",
    "    train = train[~train['Embarked'].isnull()]\n",
    "    train = train.drop('Cabin', axis=1)\n",
    "    train = train.drop(['Name', 'Sex', 'Embarked', 'Ticket'], axis=1)\n",
    "    train = train.drop('PassengerId', axis=1)\n",
    "    target = train['Survived'].to_frame()\n",
    "    features = train.drop('Survived', axis=1)\n",
    "    return features, target\n",
    "\n",
    "data = pd.read_csv('data/train.csv')\n",
    "train, test = train_test_split(data, test_size=0.15)\n",
    "assert train.shape[0] > test.shape[0]\n",
    "\n",
    "features_tr, target_tr = pipeline(train)\n",
    "features_te, target_te = pipeline(test)\n",
    "\n",
    "mdl = DummyClassifier()\n",
    "mdl = mdl.fit(features_tr, target_tr)\n",
    "print(mdl.score(features_tr, target_tr))\n",
    "print(mdl.score(features_te, target_te))\n",
    "\n",
    "mdl = RandomForestClassifier()\n",
    "mdl = mdl.fit(features_tr, target_tr)\n",
    "print(mdl.score(features_tr, target_tr))\n",
    "print(mdl.score(features_te, target_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ceec0",
   "metadata": {},
   "source": [
    "## Second Pipeline\n",
    "\n",
    "For a second pipeline, we want to add:\n",
    "\n",
    "- missing value imputation,\n",
    "- categorical features,\n",
    "- logistic regression,\n",
    "- grid searching for hyperparameters.\n",
    "\n",
    "### Small Refactor\n",
    "\n",
    "Let's start with a small refactor of data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdbf9270-7d79-4f98-ac76-978370ae092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv('data/train.csv')\n",
    "    train, test = train_test_split(data, test_size=0.15, random_state=42)\n",
    "    assert train.shape[0] > test.shape[0]\n",
    "    return train, test\n",
    "\n",
    "train, test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde5e34",
   "metadata": {},
   "source": [
    "### Missing Value Imputation\n",
    "\n",
    "In our first iteration, we dropped some samples due to missing values.\n",
    "\n",
    "We will impute the missing values in the `Age` column using the median age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4601fe88-6c65-49a9-ac31-e5e1194d2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(train, test):\n",
    "    train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "    test['Age'] = test['Age'].fillna(train['Age'].median())\n",
    "    return train, test\n",
    "\n",
    "train, test = load_data()\n",
    "train, test = impute_age(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b5069",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables\n",
    "\n",
    "To include categorical variables in our model, we will apply one-hot encoding to the 'Sex' and 'Embarked' columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6c97af9-e57b-45ec-ac6b-f7a516a42cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def encode_categorical(train, test):\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('one_hot', ohe, ['Sex', 'Embarked'])\n",
    "        ],\n",
    "        remainder='passthrough',\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "    # Fit the transformer on the train dataset and transform both train and test datasets\n",
    "    column_transformer.fit(train)\n",
    "    train_transformed = column_transformer.transform(train)\n",
    "    test_transformed = column_transformer.transform(test)\n",
    "\n",
    "    # Get the new column names after encoding\n",
    "    columns = column_transformer.get_feature_names_out(input_features=train.columns)\n",
    "\n",
    "    # Convert the transformed datasets back to DataFrames\n",
    "    train_encoded = pd.DataFrame(train_transformed, columns=columns, index=train.index)\n",
    "    test_encoded = pd.DataFrame(test_transformed, columns=columns, index=test.index)\n",
    "\n",
    "    return train_encoded, test_encoded\n",
    "\n",
    "train, test = load_data()\n",
    "train, test = encode_categorical(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f14b2",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "In addition to the Random Forest model, we will also use Logistic Regression as a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa390300-b380-42c3-a5b1-c649d389e0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7067545304777595"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mdl = LogisticRegression()\n",
    "mdl.fit(features_tr, target_tr)\n",
    "mdl.score(features_tr, target_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0874ae",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Let's find good hyperparameters for our models using grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fea18eb9-137c-4798-9b52-712b3a0a0e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n",
      "best random forest params: {'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "best logistic regression params: {'C': 1, 'max_iter': 1000, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search(mdl, param_grid, features, target):\n",
    "    grid = GridSearchCV(estimator=mdl, param_grid=param_grid, cv=2, verbose=1)\n",
    "    grid.fit(features_tr, target_tr.values.reshape(-1, ))\n",
    "    return grid.best_params_\n",
    "\n",
    "# Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "mdl_rf = RandomForestClassifier()\n",
    "best_rf_params = grid_search(mdl_rf, param_grid_rf, features_tr, target_tr)\n",
    "print(f\"best random forest params: {best_rf_params}\")\n",
    "\n",
    "# Logistic Regression\n",
    "param_grid_log = {\n",
    "    'C': [0.001, 0.1, 1, 100],\n",
    "    'penalty': [None, 'l2'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "mdl_log = LogisticRegression()\n",
    "best_log_params = grid_search(mdl_log, param_grid_log, features_tr, target_tr)\n",
    "print(f\"best logistic regression params: {best_log_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b917c6",
   "metadata": {},
   "source": [
    "### Second Pipeline\n",
    "\n",
    "Now we will combine all the new steps into the second pipeline function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51b2a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6221928665785997\n",
      "0.582089552238806\n",
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/c32cvsld7_sfp274f4bgdrrr0000gn/T/ipykernel_19427/80939396.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  mdl_rf = mdl_rf.fit(features_tr, target_tr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982826948480845\n",
      "0.8283582089552238\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8018494055482166\n",
      "0.8059701492537313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/3.10.6/envs/general/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "def pipeline(train, test):\n",
    "    train, test = encode_categorical(train, test)\n",
    "    train, test = impute_age(train, test)\n",
    "    train = train.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "    test = test.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "\n",
    "    #  need the .astype as our encode_categorical passes through as float\n",
    "    target_tr = train['Survived'].to_frame().astype(int)\n",
    "    target_te = test['Survived'].to_frame().astype(int)\n",
    "\n",
    "    features_tr = train.drop('Survived', axis=1)\n",
    "    features_te = test.drop('Survived', axis=1)\n",
    "    return features_tr, target_tr, features_te, target_te\n",
    "\n",
    "train, test = load_data()\n",
    "features_tr, target_tr, features_te, target_te = pipeline(train, test)\n",
    "\n",
    "# Dummy Classifier\n",
    "mdl = DummyClassifier()\n",
    "mdl = mdl.fit(features_tr, target_tr)\n",
    "print(mdl.score(features_tr, target_tr))\n",
    "print(mdl.score(features_te, target_te))\n",
    "\n",
    "# Random Forest\n",
    "params = grid_search(RandomForestClassifier(), param_grid_rf, features_tr, target_tr)\n",
    "mdl_rf = RandomForestClassifier(**params)\n",
    "mdl_rf = mdl_rf.fit(features_tr, target_tr)\n",
    "print(mdl_rf.score(features_tr, target_tr))\n",
    "print(mdl_rf.score(features_te, target_te))\n",
    "\n",
    "# Logistic Regression\n",
    "params = grid_search(LogisticRegression(), param_grid_log, features_tr, target_tr)\n",
    "mdl_log = LogisticRegression(**params)\n",
    "mdl_log = mdl_log.fit(features_tr, target_tr)\n",
    "print(mdl_log.score(features_tr, target_tr))\n",
    "print(mdl_log.score(features_te, target_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb30d36",
   "metadata": {},
   "source": [
    "We end our project with an 82% accuracy with our random forest - a nice improvement over our 58% for the baseline or the 68% we got with a random forest in our first iteration.\n",
    "\n",
    "## Now It's Your Turn\n",
    "\n",
    "Time for a third iteration!  \n",
    "\n",
    "Take the code developed above and add to it:\n",
    "\n",
    "- better data cleaning,\n",
    "- more feature engineering,\n",
    "- different models,\n",
    "- different grid searches.\n",
    "\n",
    "You can explore & learn from [other people's solutions on Kaggle](https://www.kaggle.com/competitions/titanic/code) as well."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
